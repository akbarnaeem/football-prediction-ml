from sklearn.metrics import accuracy_score, confusion_matrix

def make_predictions(model, X_test, y_test):
    print("\nğŸ” Evaluating model...")
    predictions = model.predict(X_test)
    acc = accuracy_score(y_test, predictions)
    print(f"âœ… Model Accuracy: {acc:.2f}")

    print("\nğŸ“Š Confusion Matrix:")
    print(confusion_matrix(y_test, predictions))

def predict_user_match(model, team_stats):
    home_team = input("\nEnter Home Team: ").strip()
    away_team = input("Enter Away Team: ").strip()

    if home_team not in team_stats.index or away_team not in team_stats.index:
        print("âŒ One or both team names are not in the available stats.")
        return

    new_match = {
        'HomeTeamStrength': team_stats.loc[home_team, 'AvgHomeGoals'],
        'AwayTeamDefense': team_stats.loc[away_team, 'AvgAwayGoals'],
        'HomeShots': team_stats.loc[home_team, 'AvgHomeShots'],
        'AwayShots': team_stats.loc[away_team, 'AvgAwayShots'],
    }

    input_df = pd.DataFrame([new_match])
    prediction = model.predict(input_df)[0]

    label_map = {0: f"ğŸ  {home_team} wins (Home Win)",
                 1: "âš– Draw",
                 2: f"âœˆ {away_team} wins (Away Win)"}

    print(f"\nğŸ“Š Prediction: {home_team} vs {away_team} â†’ {label_map[prediction]}")
